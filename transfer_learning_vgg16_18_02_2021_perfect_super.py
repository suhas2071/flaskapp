# -*- coding: utf-8 -*-
"""Transfer_Learning_VGG16_18_02_2021_Perfect_Super.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rzUQ6FNSgtjgDDRFFJV4vKGbPrJ6dtzy

## Transfer Learning VGG 16 and VGG 19 using Keras
"""

import tensorflow as tf
print(tf.__version__)

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/MyDrive

!unzip Datasets.zip

# import the libraries as shown below

from tensorflow.keras.layers import Input, Lambda, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img
from tensorflow.keras.models import Sequential
import numpy as np
from glob import glob
#import matplotlib.pyplot as plt

# re-size all the images to this
IMAGE_SIZE = [224, 224]

train_path = 'Datasets/Train'
valid_path = 'Datasets/Test'

# Import the VGG16 library as shown below and add preprocessing layer to the front of VGG
# Here we will be using imagenet weights

vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)

# don't train existing weights
for layer in vgg16.layers:
    layer.trainable = False

for layer in vgg16.layers:
    print(layer)

# useful for getting number of output classes
folders = glob('Datasets/Train/*')

folders

# our layers - you can add more if you want
x = Flatten()(vgg16.output)

len(folders)

prediction = Dense(len(folders), activation='softmax')(x)

# create a model object
model = Model(inputs=vgg16.input, outputs=prediction)

# view the structure of the model
model.summary()

# tell the model what cost and optimization method to use
model.compile(
  loss='categorical_crossentropy',
  optimizer='adam',
  metrics=['accuracy']
)

# Use the Image Data Generator to import the images from the dataset
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)

test_datagen = ImageDataGenerator(rescale = 1./255)

# Make sure you provide the same target size as initialied for the image size
training_set = train_datagen.flow_from_directory('Datasets/Train',
                                                 target_size = (224, 224),
                                                 batch_size = 32,
                                                 class_mode = 'categorical')

test_set = test_datagen.flow_from_directory('Datasets/Test',
                                            target_size = (224, 224),
                                            batch_size = 32,
                                            class_mode = 'categorical')

# fit the model
# Run the cell. It will take some time to execute
r = model.fit_generator(
  training_set,
  validation_data=test_set,
  epochs=20,
  steps_per_epoch=len(training_set),
  validation_steps=len(test_set)
)

import numpy as np
from keras.preprocessing import image
print(training_set.class_indices)

import matplotlib.pyplot as plt

# plot the loss
plt.plot(r.history['loss'], label='train loss')
plt.plot(r.history['val_loss'], label='val loss')
plt.legend()
plt.show()
plt.savefig('LossVal_loss')

# plot the accuracy
plt.plot(r.history['accuracy'], label='train acc')
plt.plot(r.history['val_accuracy'], label='val acc')
plt.legend()
plt.show()
plt.savefig('AccVal_acc')

# save it as a h5 file


from tensorflow.keras.models import load_model

model.save('model_vgg16.h5')

y_pred = model.predict(test_set)

y_pred

import numpy as np
y_pred = np.argmax(y_pred, axis=1)

y_pred

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image

model=load_model('model_vgg16.h5')

img=image.load_img('/content/mer1.jpg',target_size=(224,224))

x=image.img_to_array(img)
x

x.shape

x=x/255

import numpy as np
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
x=np.expand_dims(x,axis=0)
img_data=preprocess_input(x)
img_data.shape
#https://stackoverflow.com/questions/47555829/preprocess-input-method-in-keras/47556342#:~:text=Keras%20works%20with%20batches%20of,size1%2Csize2%2Cchannels)%20.&text=The%20preprocess_input%20function%20is%20meant,the%20format%20the%20model%20requires.

model.predict(img_data)